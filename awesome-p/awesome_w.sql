-- MySQL dump 10.16  Distrib 10.1.19-MariaDB, for Win32 (AMD64)
--
-- Host: localhost    Database: localhost
-- ------------------------------------------------------
-- Server version	10.1.19-MariaDB

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `blogs`
--

DROP TABLE IF EXISTS `blogs`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `blogs` (
  `id` varchar(50) NOT NULL,
  `user_id` varchar(50) NOT NULL,
  `user_name` varchar(50) NOT NULL,
  `user_image` varchar(500) NOT NULL,
  `name` varchar(50) NOT NULL,
  `summary` varchar(200) NOT NULL,
  `content` mediumtext NOT NULL,
  `created_at` double NOT NULL,
  PRIMARY KEY (`id`),
  KEY `idx_created_at` (`created_at`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `blogs`
--

LOCK TABLES `blogs` WRITE;
/*!40000 ALTER TABLE `blogs` DISABLE KEYS */;
INSERT INTO `blogs` VALUES ('0015236923947921167d942d8b74273a19228809a3ffd34000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','first day','on the way','I\'m suffer a diffcult period.',1523692394.78546),('001523710657519d59e4798dca94f75900b8472b2d66c3a000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','install gcc compiler','gcc','from CentOS7 system mirror take out belown rpm:\nmpfr-3.1.1-4.el7.x86_64.rpm\nlibmpc-1.0.1-3.el7.x86_64.rpm\nkernel-headers-3.10.0-123.el7.x86_64.rpm\nglibc-headers-2.17-55.el7.x86_64.rpm\nglibc-devel-2.17-55.el7.x86_64.rpm\ncpp-4.8.2-16.el7.x86_64.rpm\ngcc-4.8.2-16.el7.x86_64.rpm\n\nput them in install system.\ninput belown order in teminal:\nrpm -Uvh *.rpm --nodeps --force\n\ncheck:\ngcc -v',1523710657.51644),('001523803078345fc9702fd65754eccac8e224e90af4230000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','centos order','centos','find files: find / -name\nkill process: kill -9\ncheck file\'s right: ls -l\nmake directory: mkdir\ncheck addres: netstat -ntlp\ncheck directory: pwd\nmake files: touch\nedit files: vim',1523803078.34433),('0015238407671360e1489a4048e423fb0636d403975d647000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','nginx directery','nginx','nginx: /usr/sbin/nginx   /usr/lib64/nginx   /etc/nginx   /usr/share/nginx   /usr/share/man/man3/nginx.3pm.gz   /usr/share/man/man8/nginx.8.gz',1523840767.13593),('001523842318776bc3415be6a5e40a1908ba7b07a344acc000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','nginx Configuration File鈥檚 Structure','nginx','nginx consists of modules which are controlled by directives specified in the configuration file. Directives are divided into simple directives and block directives. A simple directive consists of the name and parameters separated by spaces and ends with a semicolon (;). A block directive has the same structure as a simple directive, but instead of the semicolon it ends with a set of additional instructions surrounded by braces ({ and }). If a block directive can have other directives inside braces, it is called a context (examples: events, http, server, and location). \nDirectives placed in the configuration file outside of any contexts are considered to be in the main context. The events and http directives reside in the main context, server in http, and location in server. \nThe rest of a line after the # sign is considered a comment.',1523842318.77698),('00152384252911426bf972fabe64ca4b60a04d00062bf78000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','nginx Setting Up a Simple Proxy Server','nginx','One of the frequent uses of nginx is setting it up as a proxy server, which means a server that receives requests, passes them to the proxied servers, retrieves responses from them, and sends them to the clients. \nWe will configure a basic proxy server, which serves requests of images with files from the local directory and sends all other requests to a proxied server. In this example, both servers will be defined on a single nginx instance. \nFirst, define the proxied server by adding one more server block to the nginx鈥檚 configuration file with the following contents: \nserver {\n    listen 8080;\n    root /data/up1;\n\n    location / {\n    }\n}\nThis will be a simple server that listens on the port 8080 (previously, the listen directive has not been specified since the standard port 80 was used) and maps all requests to the /data/up1 directory on the local file system. Create this directory and put the index.html file into it. Note that the root directive is placed in the server context. Such root directive is used when the location block selected for serving a request does not include own root directive. \nNext, use the server configuration from the previous section and modify it to make it a proxy server configuration. In the first location block, put the proxy_pass directive with the protocol, name and port of the proxied server specified in the parameter (in our case, it is http://localhost:8080): \nserver {\n    location / {\n        proxy_pass http://localhost:8080;\n    }\n\n    location /images/ {\n        root /data;\n    }\n}\n\nWe will modify the second location block, which currently maps requests with the /images/ prefix to the files under the /data/images directory, to make it match the requests of images with typical file extensions. The modified location block looks like this: \nlocation ~ \\.(gif|jpg|png)$ {\n    root /data/images;\n}\nThe parameter is a regular expression matching all URIs ending with .gif, .jpg, or .png. A regular expression should be preceded with ~. The corresponding requests will be mapped to the /data/images directory. \nWhen nginx selects a location block to serve a request it first checks location directives that specify prefixes, remembering location with the longest prefix, and then checks regular expressions. If there is a match with a regular expression, nginx picks this location or, otherwise, it picks the one remembered earlier. \nThe resulting configuration of a proxy server will look like this: \nserver {\n    location / {\n        proxy_pass http://localhost:8080/;\n    }\n\n    location ~ \\.(gif|jpg|png)$ {\n        root /data/images;\n    }\n}\nThis server will filter requests ending with .gif, .jpg, or .png and map them to the /data/images directory (by adding URI to the root directive鈥檚 parameter) and pass all other requests to the proxied server configured above. \nTo apply new configuration, send the reload signal to nginx as described in the previous sections. \nThere are many more directives that may be used to further configure a proxy connection.',1523842529.11395),('0015238485977060a1271c836664d8f9c6eb4b14f5fc7cb000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','CentOS Linux','CentOS','CentOS Linux is a community-supported distribution derived from sources freely provided to the public by Red Hat for Red Hat Enterprise Linux (RHEL). As such, CentOS Linux aims to be functionally compatible with RHEL. The CentOS Project mainly changes packages to remove upstream vendor branding and artwork. CentOS Linux is no-cost and free to redistribute. Each CentOS version is maintained for up to 10 years (by means of security updates -- the duration of the support interval by Red Hat has varied over time with respect to Sources released). A new CentOS version is released approximately every 2 years and each CentOS version is periodically updated (roughly every 6 months) to support newer hardware. This results in a secure, low-maintenance, reliable, predictable and reproducible Linux environment.',1523848597.7051),('00152385348499342927120b65c436e909134c454fa3ce3000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','ngnix Command-line parameters','ngnix','Command-line parameters\nnginx supports the following command-line parameters: \n-? | -h 鈥?print help for command-line parameters. \n-c file 鈥?use an alternative configuration file instead of a default file. \n-g directives 鈥?set global configuration directives, for example, \nnginx -g \"pid /var/run/nginx.pid; worker_processes `sysctl -n hw.ncpu`;\"\n-p prefix 鈥?set nginx path prefix, i.e. a directory that will keep server files (default value is /usr/local/nginx). \n-q 鈥?suppress non-error messages during configuration testing. \n-s signal 鈥?send a signal to the master process. The argument signal can be one of: \nstop 鈥?shut down quickly \nquit 鈥?shut down gracefully \nreload 鈥?reload configuration, start the new worker process with a new configuration, gracefully shut down old worker processes. \nreopen 鈥?reopen log files \n-t 鈥?test the configuration file: nginx checks the configuration for correct syntax, and then tries to open files referred in the configuration. \n-T 鈥?same as -t, but additionally dump configuration files to standard output (1.9.2). \n-v 鈥?print nginx version. \n-V 鈥?print nginx version, compiler version, and configure parameters.',1523853484.99396),('001523880632400fbc385108d1e453a98a6b9e2fdc521d8000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','python铏氭嫙鐜--virtualenv','virtualenv','python铏氭嫙鐜--virtualenv \n\n銆€銆€virtualenv 鏄竴涓垱寤洪殧缁濈殑Python鐜鐨勫伐鍏枫€倂irtualenv鍒涘缓涓€涓寘鍚墍鏈夊繀瑕佺殑鍙墽琛屾枃浠剁殑鏂囦欢澶癸紝鐢ㄦ潵浣跨敤Python宸ョ▼鎵€闇€鐨勫寘銆俓n銆€銆€瀹夎\npip install virtualenv\n銆€銆€鍩烘湰浣跨敤\n涓轰竴涓伐绋嬪垱寤轰竴涓櫄鎷熺幆澧冿細\n$ cd my_project_dir\n$ virtualenv venv銆€銆€#venv涓鸿櫄鎷熺幆澧冪洰褰曞悕锛岀洰褰曞悕鑷畾涔塡n銆€銆€virtualenv venv 灏嗕細鍦ㄥ綋鍓嶇殑鐩綍涓垱寤轰竴涓枃浠跺す锛屽寘鍚簡Python鍙墽琛屾枃浠讹紝浠ュ強 pip 搴撶殑涓€浠芥嫹璐濓紝杩欐牱灏辫兘瀹夎鍏朵粬鍖呬簡銆傝櫄鎷熺幆澧冪殑鍚嶅瓧锛堟渚嬩腑鏄?venv 锛夊彲浠ユ槸浠绘剰鐨勶紱鑻ョ渷鐣ュ悕瀛楀皢浼氭妸鏂囦欢鍧囨斁鍦ㄥ綋鍓嶇洰褰曘€俓n銆€銆€鍦ㄤ换浣曚綘杩愯鍛戒护鐨勭洰褰曚腑锛岃繖浼氬垱寤篜ython鐨勬嫹璐濓紝骞跺皢涔嬫斁鍦ㄥ彨鍋?venv 鐨勬枃浠朵腑銆俓n銆€銆€浣犲彲浠ラ€夋嫨浣跨敤涓€涓狿ython瑙ｉ噴鍣細\n$ virtualenv -p /usr/bin/python2.7 venv銆€銆€銆€銆€# -p鍙傛暟鎸囧畾Python瑙ｉ噴鍣ㄧ▼搴忚矾寰刓n銆€銆€杩欏皢浼氫娇鐢?/usr/bin/python2.7 涓殑Python瑙ｉ噴鍣ㄣ€俓n \n瑕佸紑濮嬩娇鐢ㄨ櫄鎷熺幆澧冿紝鍏堕渶瑕佽婵€娲伙細\n$ source venv/bin/activate銆€銆€銆€\n浠庣幇鍦ㄨ捣锛屼换浣曚綘浣跨敤pip瀹夎鐨勫寘灏嗕細鏀惧湪 venv 鏂囦欢澶逛腑锛屼笌鍏ㄥ眬瀹夎鐨凱ython闅旂粷寮€銆俓n鍍忓钩甯镐竴鏍峰畨瑁呭寘锛屾瘮濡傦細\n$ pip install requests\n濡傛灉浣犲湪铏氭嫙鐜涓殏鏃跺畬鎴愪簡宸ヤ綔锛屽垯鍙互鍋滅敤瀹冿細\n$ . venv/bin/deactivate\n杩欏皢浼氬洖鍒扮郴缁熼粯璁ょ殑Python瑙ｉ噴鍣紝鍖呮嫭宸插畨瑁呯殑搴撲篃浼氬洖鍒伴粯璁ょ殑銆俓n瑕佸垹闄や竴涓櫄鎷熺幆澧冿紝鍙渶鍒犻櫎瀹冪殑鏂囦欢澶广€傦紙鎵ц rm -rf venv 锛夈€俓n杩欓噷virtualenv 鏈変簺涓嶄究锛屽洜涓簐irtual鐨勫惎鍔ㄣ€佸仠姝㈣剼鏈兘鍦ㄧ壒瀹氭枃浠跺す锛屽彲鑳戒竴娈垫椂闂村悗锛屼綘鍙兘浼氭湁寰堝涓櫄鎷熺幆澧冩暎钀藉湪绯荤粺鍚勫锛屼綘鍙兘蹇樿瀹冧滑鐨勫悕瀛楁垨鑰呬綅缃€俓nvirtualenvwrapper\n銆€銆€閴翠簬virtualenv涓嶄究浜庡铏氭嫙鐜闆嗕腑绠＄悊锛屾墍浠ユ帹鑽愮洿鎺ヤ娇鐢╲irtualenvwrapper銆?virtualenvwrapper鎻愪緵浜嗕竴绯诲垪鍛戒护浣垮緱鍜岃櫄鎷熺幆澧冨伐浣滃彉寰椾究鍒┿€傚畠鎶婁綘鎵€鏈夌殑铏氭嫙鐜閮芥斁鍦ㄤ竴涓湴鏂广€俓n銆€銆€瀹夎virtualenvwrapper(纭繚virtualenv宸插畨瑁?\npip install virtualenvwrapper\npip install virtualenvwrapper-win銆€銆€#Windows浣跨敤璇ュ懡浠n銆€銆€瀹夎瀹屾垚鍚庯紝鍦▇/.bashrc鍐欏叆浠ヤ笅鍐呭\nexport WORKON_HOME=~/Envs\nsource /usr/local/bin/virtualenvwrapper.sh銆€銆€\n銆€銆€绗竴琛岋細virtualenvwrapper瀛樻斁铏氭嫙鐜鐩綍\n銆€銆€绗簩琛岋細virtrualenvwrapper浼氬畨瑁呭埌python鐨刡in鐩綍涓嬶紝鎵€浠ヨ璺緞鏄痯ython瀹夎鐩綍涓媌in/virtualenvwrapper.sh\nsource ~/.bashrc銆€銆€銆€銆€#璇诲叆閰嶇疆鏂囦欢锛岀珛鍗崇敓鏁圽n銆€\n銆€virtualenvwrapper鍩烘湰浣跨敤\n1.鍒涘缓铏氭嫙鐜銆€mkvirtualenv\nmkvirtualenv venv銆€銆€銆€\n銆€銆€杩欐牱浼氬湪WORKON_HOME鍙橀噺鎸囧畾鐨勭洰褰曚笅鏂板缓鍚嶄负venv鐨勮櫄鎷熺幆澧冦€俓n銆€銆€鑻ユ兂鎸囧畾python鐗堟湰锛屽彲閫氳繃\"--python\"鎸囧畾python瑙ｉ噴鍣╘nmkvirtualenv --python=/usr/local/python3.5.3/bin/python venv\n2. 鍩烘湰鍛戒护 銆€\n銆€銆€鏌ョ湅褰撳墠鐨勮櫄鎷熺幆澧冪洰褰昞n[root@localhost ~]# workon\npy2\npy3\n銆€銆€鍒囨崲鍒拌櫄鎷熺幆澧僜n[root@localhost ~]# workon py3\n(py3) [root@localhost ~]# \n銆€銆€閫€鍑鸿櫄鎷熺幆澧僜n(py3) [root@localhost ~]# deactivate\n[root@localhost ~]# \n銆€銆€鍒犻櫎铏氭嫙鐜\nrmvirtualenv venv',1523880632.39964),('00152404617202386c05cc50188402089e52794eb595e55000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','execution model','fabric','Execution model\nIf you鈥檝e read the Overview and Tutorial, you should already be familiar with how Fabric operates in the base case (a single task on a single host.) However, in many situations you鈥檒l find yourself wanting to execute multiple tasks and/or on multiple hosts. Perhaps you want to split a big task into smaller reusable parts, or crawl a collection of servers looking for an old user to remove. Such a scenario requires specific rules for when and how tasks are executed.\nThis document explores Fabric鈥檚 execution model, including the main execution loop, how to define host lists, how connections are made, and so forth.\nExecution strategy\nFabric defaults to a single, serial execution method, though there is an alternative parallel mode available as of Fabric 1.3 (see Parallel execution). This default behavior is as follows:\nA list of tasks is created. Currently this list is simply the arguments given to fab, preserving the order given.\nFor each task, a task-specific host list is generated from various sources (see How host lists are constructed below for details.)\nThe task list is walked through in order, and each task is run once per host in its host list.\nTasks with no hosts in their host list are considered local-only, and will always run once and only once.\nThus, given the following fabfile:\nfrom fabric.api import run, env\n\nenv.hosts = [\'host1\', \'host2\']\n\ndef taskA():\n    run(\'ls\')\n\ndef taskB():\n    run(\'whoami\')\nand the following invocation:\n$ fab taskA taskB\nyou will see that Fabric performs the following:\ntaskA executed on host1\ntaskA executed on host2\ntaskB executed on host1\ntaskB executed on host2\nWhile this approach is simplistic, it allows for a straightforward composition of task functions, and (unlike tools which push the multi-host functionality down to the individual function calls) enables shell script-like logic where you may introspect the output or return code of a given command and decide what to do next.\nDefining tasks\nFor details on what constitutes a Fabric task and how to organize them, please see Defining tasks.\nDefining host lists\nUnless you鈥檙e using Fabric as a simple build system (which is possible, but not the primary use-case) having tasks won鈥檛 do you any good without the ability to specify remote hosts on which to execute them. There are a number of ways to do so, with scopes varying from global to per-task, and it鈥檚 possible mix and match as needed.\nHosts\nHosts, in this context, refer to what are also called 鈥渉ost strings鈥? Python strings specifying a username, hostname and port combination, in the form of username@hostname:port. User and/or port (and the associated @ or :) may be omitted, and will be filled by the executing user鈥檚 local username, and/or port 22, respectively. Thus, admin@foo.com:222, deploy@website and nameserver1 could all be valid host strings.\nIPv6 address notation is also supported, for example ::1, [::1]:1222, user@2001:db8::1 or user@[2001:db8::1]:1222. Square brackets are necessary only to separate the address from the port number. If no port number is used, the brackets are optional. Also if host string is specified via command-line argument, it may be necessary to escape brackets in some shells.\nNote \nThe user/hostname split occurs at the last @ found, so e.g. email address usernames are valid and will be parsed correctly.\nDuring execution, Fabric normalizes the host strings given and then stores each part (username/hostname/port) in the environment dictionary, for both its use and for tasks to reference if the need arises. See The environment dictionary, env for details.\nRoles\nHost strings map to single hosts, but sometimes it鈥檚 useful to arrange hosts in groups. Perhaps you have a number of Web servers behind a load balancer and want to update all of them, or want to run a task on 鈥渁ll client servers鈥? Roles provide a way of defining strings which correspond to lists of host strings, and can then be specified instead of writing out the entire list every time.\nThis mapping is defined as a dictionary, env.roledefs, which must be modified by a fabfile in order to be used. A simple example:\nfrom fabric.api import env\n\nenv.roledefs[\'webservers\'] = [\'www1\', \'www2\', \'www3\']\nSince env.roledefs is naturally empty by default, you may also opt to re-assign to it without fear of losing any information (provided you aren鈥檛 loading other fabfiles which also modify it, of course):\nfrom fabric.api import env\n\nenv.roledefs = {\n    \'web\': [\'www1\', \'www2\', \'www3\'],\n    \'dns\': [\'ns1\', \'ns2\']\n}\nRole definitions are not necessarily configuration of hosts only, they can also hold additional role specific settings of your choice. This is achieved by defining the roles as dicts and host strings under a hosts key:\nfrom fabric.api import env\n\nenv.roledefs = {\n    \'web\': {\n        \'hosts\': [\'www1\', \'www2\', \'www3\'],\n        \'foo\': \'bar\'\n    },\n    \'dns\': {\n        \'hosts\': [\'ns1\', \'ns2\'],\n        \'foo\': \'baz\'\n    }\n}\nIn addition to list/iterable object types, the values in env.roledefs (or value of hosts key in dict style definition) may be callables, and will thus be called when looked up when tasks are run instead of at module load time. (For example, you could connect to remote servers to obtain role definitions, and not worry about causing delays at fabfile load time when calling e.g. fab --list.)\nUse of roles is not required in any way 鈥?it鈥檚 simply a convenience in situations where you have common groupings of servers.\nChanged in version 0.9.2: Added ability to use callables as roledefs values.\nHow host lists are constructed\nThere are a number of ways to specify host lists, either globally or per-task, and generally these methods override one another instead of merging together (though this may change in future releases.) Each such method is typically split into two parts, one for hosts and one for roles.\nGlobally, via env\nThe most common method of setting hosts or roles is by modifying two key-value pairs in the environment dictionary, env: hosts and roles. The value of these variables is checked at runtime, while constructing each tasks鈥檚 host list.\nThus, they may be set at module level, which will take effect when the fabfile is imported:\nfrom fabric.api import env, run\n\nenv.hosts = [\'host1\', \'host2\']\n\ndef mytask():\n    run(\'ls /var/www\')\nSuch a fabfile, run simply as fab mytask, will run mytask on host1 followed by host2.\nSince the env vars are checked for each task, this means that if you have the need, you can actually modify env in one task and it will affect all following tasks:\nfrom fabric.api import env, run\n\ndef set_hosts():\n    env.hosts = [\'host1\', \'host2\']\n\ndef mytask():\n    run(\'ls /var/www\')\nWhen run as fab set_hosts mytask, set_hosts is a 鈥渓ocal鈥?task 鈥?its own host list is empty 鈥?but mytask will again run on the two hosts given.\nNote \nThis technique used to be a common way of creating fake 鈥渞oles鈥? but is less necessary now that roles are fully implemented. It may still be useful in some situations, however.\nAlongside env.hosts is env.roles (not to be confused with env.roledefs!) which, if given, will be taken as a list of role names to look up in env.roledefs.\nGlobally, via the command line\nIn addition to modifying env.hosts, env.roles, and env.exclude_hosts at the module level, you may define them by passing comma-separated string arguments to the command-line switches --hosts/-H and --roles/-R, e.g.:\n$ fab -H host1,host2 mytask\nSuch an invocation is directly equivalent to env.hosts = [\'host1\', \'host2\'] 鈥?the argument parser knows to look for these arguments and will modify env at parse time.\nNote \nIt鈥檚 possible, and in fact common, to use these switches to set only a single host or role. Fabric simply calls string.split(\',\') on the given string, so a string with no commas turns into a single-item list.\nIt is important to know that these command-line switches are interpreted before your fabfile is loaded: any reassignment to env.hosts or env.roles in your fabfile will overwrite them.\nIf you wish to nondestructively merge the command-line hosts with your fabfile-defined ones, make sure your fabfile uses env.hosts.extend() instead:\nfrom fabric.api import env, run\n\nenv.hosts.extend([\'host3\', \'host4\'])\n\ndef mytask():\n    run(\'ls /var/www\')\nWhen this fabfile is run as fab -H host1,host2 mytask, env.hosts will then contain [\'host1\', \'host2\', \'host3\', \'host4\'] at the time that mytask is executed.\nNote \nenv.hosts is simply a Python list object 鈥?so you may use env.hosts.append() or any other such method you wish.\nPer-task, via the command line\nGlobally setting host lists only works if you want all your tasks to run on the same host list all the time. This isn鈥檛 always true, so Fabric provides a few ways to be more granular and specify host lists which apply to a single task only. The first of these uses task arguments.\nAs outlined in fab options and arguments, it鈥檚 possible to specify per-task arguments via a special command-line syntax. In addition to naming actual arguments to your task function, this may be used to set the host, hosts, role or roles 鈥渁rguments鈥? which are interpreted by Fabric when building host lists (and removed from the arguments passed to the task itself.)\nNote \nSince commas are already used to separate task arguments from one another, semicolons must be used in the hosts or roles arguments to delineate individual host strings or role names. Furthermore, the argument must be quoted to prevent your shell from interpreting the semicolons.\nTake the below fabfile, which is the same one we鈥檝e been using, but which doesn鈥檛 define any host info at all:\nfrom fabric.api import run\n\ndef mytask():\n    run(\'ls /var/www\')\nTo specify per-task hosts for mytask, execute it like so:\n$ fab mytask:hosts=\"host1;host2\"\nThis will override any other host list and ensure mytask always runs on just those two hosts.\nPer-task, via decorators\nIf a given task should always run on a predetermined host list, you may wish to specify this in your fabfile itself. This can be done by decorating a task function with the hosts or roles decorators. These decorators take a variable argument list, like so:\nfrom fabric.api import hosts, run\n\n@hosts(\'host1\', \'host2\')\ndef mytask():\n    run(\'ls /var/www\')\nThey will also take an single iterable argument, e.g.:\nmy_hosts = (\'host1\', \'host2\')\n@hosts(my_hosts)\ndef mytask():\n    # ...\nWhen used, these decorators override any checks of env for that particular task鈥檚 host list (though env is not modified in any way 鈥?it is simply ignored.) Thus, even if the above fabfile had defined env.hosts or the call to fab uses --hosts/-H, mytask would still run on a host list of [\'host1\', \'host2\'].\nHowever, decorator host lists do not override per-task command-line arguments, as given in the previous section.\nOrder of precedence\nWe鈥檝e been pointing out which methods of setting host lists trump the others, as we鈥檝e gone along. However, to make things clearer, here鈥檚 a quick breakdown:\nPer-task, command-line host lists (fab mytask:host=host1) override absolutely everything else.\nPer-task, decorator-specified host lists (@hosts(\'host1\')) override the env variables.\nGlobally specified host lists set in the fabfile (env.hosts = [\'host1\']) can override such lists set on the command-line, but only if you鈥檙e not careful (or want them to.)\nGlobally specified host lists set on the command-line (--hosts=host1) will initialize the env variables, but that鈥檚 it.\nThis logic may change slightly in the future to be more consistent (e.g. having --hosts somehow take precedence over env.hosts in the same way that command-line per-task lists trump in-code ones) but only in a backwards-incompatible release.\nCombining host lists\nThere is no 鈥渦nionizing鈥?of hosts between the various sources mentioned in How host lists are constructed. If env.hosts is set to [\'host1\', \'host2\', \'host3\'], and a per-function (e.g. via hosts) host list is set to just [\'host2\', \'host3\'], that function will not execute on host1, because the per-task decorator host list takes precedence.\nHowever, for each given source, if both roles and hosts are specified, they will be merged together into a single host list. Take, for example, this fabfile where both of the decorators are used:\nfrom fabric.api import env, hosts, roles, run\n\nenv.roledefs = {\'role1\': [\'b\', \'c\']}\n\n@hosts(\'a\', \'b\')\n@roles(\'role1\')\ndef mytask():\n    run(\'ls /var/www\')\nAssuming no command-line hosts or roles are given when mytask is executed, this fabfile will call mytask on a host list of [\'a\', \'b\', \'c\'] 鈥?the union of role1 and the contents of the hosts call.\nHost list deduplication\nBy default, to support Combining host lists, Fabric deduplicates the final host list so any given host string is only present once. However, this prevents explicit/intentional running of a task multiple times on the same target host, which is sometimes useful.\nTo turn off deduplication, set env.dedupe_hosts to False.\nExcluding specific hosts\nAt times, it is useful to exclude one or more specific hosts, e.g. to override a few bad or otherwise undesirable hosts which are pulled in from a role or an autogenerated host list.\nNote \nAs of Fabric 1.4, you may wish to use skip_bad_hosts instead, which automatically skips over any unreachable hosts.\nHost exclusion may be accomplished globally with --exclude-hosts/-x:\n$ fab -R myrole -x host2,host5 mytask\nIf myrole was defined as [\'host1\', \'host2\', ..., \'host15\'], the above invocation would run with an effective host list of [\'host1\', \'host3\', \'host4\', \'host6\', ..., \'host15\'].\nNote \nUsing this option does not modify env.hosts 鈥?it only causes the main execution loop to skip the requested hosts.\nExclusions may be specified per-task by using an extra exclude_hosts kwarg, which is implemented similarly to the abovementioned hosts and roles per-task kwargs, in that it is stripped from the actual task invocation. This example would have the same result as the global exclude above:\n$ fab mytask:roles=myrole,exclude_hosts=\"host2;host5\"\nNote that the host list is semicolon-separated, just as with the hosts per-task argument.\nCombining exclusions\nHost exclusion lists, like host lists themselves, are not merged together across the different 鈥渓evels鈥?they can be declared in. For example, a global -x option will not affect a per-task host list set with a decorator or keyword argument, nor will per-task exclude_hosts keyword arguments affect a global -H list.\nThere is one minor exception to this rule, namely that CLI-level keyword arguments (mytask:exclude_hosts=x,y) will be taken into account when examining host lists set via @hosts or @roles. Thus a task function decorated with @hosts(\'host1\', \'host2\') executed as fab taskname:exclude_hosts=host2 will only run on host1.\nAs with the host list merging, this functionality is currently limited (partly to keep the implementation simple) and may be expanded in future releases.\nIntelligently executing tasks with execute\nNew in version 1.3.\nMost of the information here involves 鈥渢op level鈥?tasks executed via fab, such as the first example where we called fab taskA taskB. However, it鈥檚 often convenient to wrap up multi-task invocations like this into their own, 鈥渕eta鈥?tasks.\nPrior to Fabric 1.3, this had to be done by hand, as outlined in Library Use. Fabric鈥檚 design eschews magical behavior, so simply calling a task function does not take into account decorators such as roles.\nNew in Fabric 1.3 is the execute helper function, which takes a task object or name as its first argument. Using it is effectively the same as calling the given task from the command line: all the rules given above in How host lists are constructed apply. (The hosts and roles keyword arguments to execute are analogous to CLI per-task arguments, including how they override all other host/role-setting methods.)\nAs an example, here鈥檚 a fabfile defining two stand-alone tasks for deploying a Web application:\nfrom fabric.api import run, roles\n\nenv.roledefs = {\n    \'db\': [\'db1\', \'db2\'],\n    \'web\': [\'web1\', \'web2\', \'web3\'],\n}\n\n@roles(\'db\')\ndef migrate():\n    # Database stuff here.\n    pass\n\n@roles(\'web\')\ndef update():\n    # Code updates here.\n    pass\nIn Fabric <=1.2, the only way to ensure that migrate runs on the DB servers and that update runs on the Web servers (short of manual env.host_string manipulation) was to call both as top level tasks:\n$ fab migrate update\nFabric >=1.3 can use execute to set up a meta-task. Update the import line like so:\nfrom fabric.api import run, roles, execute\nand append this to the bottom of the file:\ndef deploy():\n    execute(migrate)\n    execute(update)\nThat鈥檚 all there is to it; the roles decorators will be honored as expected, resulting in the following execution sequence:\nmigrate on db1\nmigrate on db2\nupdate on web1\nupdate on web2\nupdate on web3\nWarning \nThis technique works because tasks that themselves have no host list (this includes the global host list settings) only run one time. If used inside a 鈥渞egular鈥?task that is going to run on multiple hosts, calls to execute will also run multiple times, resulting in multiplicative numbers of subtask calls 鈥?be careful!\nIf you would like your execute calls to only be called once, you may use the runs_once decorator.\nSee also \nexecute, runs_once\nLeveraging execute to access multi-host results\nIn nontrivial Fabric runs, especially parallel ones, you may want to gather up a bunch of per-host result values at the end - e.g. to present a summary table, perform calculations, etc.\nIt鈥檚 not possible to do this in Fabric鈥檚 default 鈥渘aive鈥?mode (one where you rely on Fabric looping over host lists on your behalf), but with execute it鈥檚 pretty easy. Simply switch from calling the actual work-bearing task, to calling a 鈥渕eta鈥?task which takes control of execution with execute:\nfrom fabric.api import task, execute, run, runs_once\n\n@task\ndef workhorse():\n    return run(\"get my infos\")\n\n@task\n@runs_once\ndef go():\n    results = execute(workhorse)\n    print results\nIn the above, workhorse can do any Fabric stuff at all 鈥?it鈥檚 literally your old 鈥渘aive鈥?task 鈥?except that it needs to return something useful.\ngo is your new entry point (to be invoked as fab go, or whatnot) and its job is to take the results dictionary from the execute call and do whatever you need with it. Check the API docs for details on the structure of that return value.\nUsing execute with dynamically-set host lists\nA common intermediate-to-advanced use case for Fabric is to parameterize lookup of one鈥檚 target host list at runtime (when use of Roles does not suffice). execute can make this extremely simple, like so:\nfrom fabric.api import run, execute, task\n\n# For example, code talking to an HTTP API, or a database, or ...\nfrom mylib import external_datastore\n\n# This is the actual algorithm involved. It does not care about host\n# lists at all.\ndef do_work():\n    run(\"something interesting on a host\")\n\n# This is the user-facing task invoked on the command line.\n@task\ndef deploy(lookup_param):\n    # This is the magic you don\'t get with @hosts or @roles.\n    # Even lazy-loading roles require you to declare available roles\n    # beforehand. Here, the sky is the limit.\n    host_list = external_datastore.query(lookup_param)\n    # Put this dynamically generated host list together with the work to be\n    # done.\n    execute(do_work, hosts=host_list)\nFor example, if external_datastore was a simplistic 鈥渓ook up hosts by tag in a database鈥?service, and you wanted to run a task on all hosts tagged as being related to your application stack, you might call the above like this:\n$ fab deploy:app\nBut wait! A data migration has gone awry on the DB servers. Let鈥檚 fix up our migration code in our source repo, and deploy just the DB boxes again:\n$ fab deploy:db\nThis use case looks similar to Fabric鈥檚 roles, but has much more potential, and is by no means limited to a single argument. Define the task however you wish, query your external data store in whatever way you need 鈥?it鈥檚 just Python.\nThe alternate approach\nSimilar to the above, but using fab鈥榮 ability to call multiple tasks in succession instead of an explicit execute call, is to mutate env.hosts in a host-list lookup task and then call do_work in the same session:\nfrom fabric.api import run, task\n\nfrom mylib import external_datastore\n\n# Marked as a publicly visible task, but otherwise unchanged: still just\n# \"do the work, let somebody else worry about what hosts to run on\".\n@task\ndef do_work():\n    run(\"something interesting on a host\")\n\n@task\ndef set_hosts(lookup_param):\n    # Update env.hosts instead of calling execute()\n    env.hosts = external_datastore.query(lookup_param)\nThen invoke like so:\n$ fab set_hosts:app do_work\nOne benefit of this approach over the previous one is that you can replace do_work with any other 鈥渨orkhorse鈥?task:\n$ fab set_hosts:db snapshot\n$ fab set_hosts:cassandra,cluster2 repair_ring\n$ fab set_hosts:redis,environ=prod status\nFailure handling\nOnce the task list has been constructed, Fabric will start executing them as outlined in Execution strategy, until all tasks have been run on the entirety of their host lists. However, Fabric defaults to a 鈥渇ail-fast鈥?behavior pattern: if anything goes wrong, such as a remote program returning a nonzero return value or your fabfile鈥檚 Python code encountering an exception, execution will halt immediately.\nThis is typically the desired behavior, but there are many exceptions to the rule, so Fabric provides env.warn_only, a Boolean setting. It defaults to False, meaning an error condition will result in the program aborting immediately. However, if env.warn_only is set to True at the time of failure 鈥?with, say, the settings context manager 鈥?Fabric will emit a warning message but continue executing.\nTo signal a failure error from a Fabric task, use the abort. abort signals an error as if it had been detected by Fabric and follows the regular execution model for control flow.\nConnections\nfab itself doesn鈥檛 actually make any connections to remote hosts. Instead, it simply ensures that for each distinct run of a task on one of its hosts, the env var env.host_string is set to the right value. Users wanting to leverage Fabric as a library may do so manually to achieve similar effects (though as of Fabric 1.3, using execute is preferred and more powerful.)\nenv.host_string is (as the name implies) the 鈥渃urrent鈥?host string, and is what Fabric uses to determine what connections to make (or re-use) when network-aware functions are run. Operations like run or put use env.host_string as a lookup key in a shared dictionary which maps host strings to SSH connection objects.\nNote \nThe connections dictionary (currently located at fabric.state.connections) acts as a cache, opting to return previously created connections if possible in order to save some overhead, and creating new ones otherwise.\nLazy connections\nBecause connections are driven by the individual operations, Fabric will not actually make connections until they鈥檙e necessary. Take for example this task which does some local housekeeping prior to interacting with the remote server:\nfrom fabric.api import *\n\n@hosts(\'host1\')\ndef clean_and_upload():\n    local(\'find assets/ -name \"*.DS_Store\" -exec rm \'{}\' \\;\')\n    local(\'tar czf /tmp/assets.tgz assets/\')\n    put(\'/tmp/assets.tgz\', \'/tmp/assets.tgz\')\n    with cd(\'/var/www/myapp/\'):\n        run(\'tar xzf /tmp/assets.tgz\')\nWhat happens, connection-wise, is as follows:\nThe two local calls will run without making any network connections whatsoever;\nput asks the connection cache for a connection to host1;\nThe connection cache fails to find an existing connection for that host string, and so creates a new SSH connection, returning it to put;\nput uploads the file through that connection;\nFinally, the run call asks the cache for a connection to that same host string, and is given the existing, cached connection for its own use.\nExtrapolating from this, you can also see that tasks which don鈥檛 use any network-borne operations will never actually initiate any connections (though they will still be run once for each host in their host list, if any.)\nClosing connections\nFabric鈥檚 connection cache never closes connections itself 鈥?it leaves this up to whatever is using it. The fab tool does this bookkeeping for you: it iterates over all open connections and closes them just before it exits (regardless of whether the tasks failed or not.)\nLibrary users will need to ensure they explicitly close all open connections before their program exits. This can be accomplished by calling disconnect_all at the end of your script.\nNote \ndisconnect_all may be moved to a more public location in the future; we鈥檙e still working on making the library aspects of Fabric more solidified and organized.\nMultiple connection attempts and skipping bad hosts\nAs of Fabric 1.4, multiple attempts may be made to connect to remote servers before aborting with an error: Fabric will try connecting env.connection_attempts times before giving up, with a timeout of env.timeout seconds each time. (These currently default to 1 try and 10 seconds, to match previous behavior, but they may be safely changed to whatever you need.)\nFurthermore, even total failure to connect to a server is no longer an absolute hard stop: set env.skip_bad_hosts to True and in most situations (typically initial connections) Fabric will simply warn and continue, instead of aborting.\nNew in version 1.4.\nPassword management\nFabric maintains an in-memory password cache of your login and sudo passwords in certain situations; this helps avoid tedious re-entry when multiple systems share the same password [1], or if a remote system鈥檚 sudo configuration doesn鈥檛 do its own caching.\nPre-filling the password caches\nThe first layer is a simple default or fallback password value, env.password (which may also be set at the command line via --password or --initial-password-prompt). This env var stores a single password which (if non-empty) will be tried in the event that the host-specific cache (see below) has no entry for the current host string.\nenv.passwords (plural!) serves as a per-user/per-host cache, storing the most recently entered password for every unique user/host/port combination (note that you must include all three values if modifying the structure by hand - see the above link for details). Due to this cache, connections to multiple different users and/or hosts in the same session will only require a single password entry for each. (Previous versions of Fabric used only the single, default password cache and thus required password re-entry every time the previously entered password became invalid.)\nAuto-filling/updating from user input\nDepending on your configuration and the number of hosts your session will connect to, you may find setting either or both of the above env vars to be useful. However, Fabric will automatically fill them in as necessary without any additional configuration.\nSpecifically, each time a password prompt is presented to the user, the value entered is used to update both the single default password cache, and the cache value for the current value of env.host_string.\nSpecifying sudo-only passwords\nIn some situations (such as those involving two-factor authentication, or any other situation where submitting a password at login time is not desired or correct) you may want to only cache passwords intended for sudo, instead of reusing the values for both login and sudo purposes.\nTo do this, you may set env.sudo_password or populate env.sudo_passwords, which mirror env.password and env.passwords (described above). These values will only be used in responding to sudo password prompts, and will never be submitted at connection time.\nThere is also an analogue to the --password command line flag, named --sudo-password, and like --initial-password-prompt, there exists --initial-sudo-password-prompt.\nNote \nWhen both types of passwords are filled in (e.g. if env.password = \"foo\" and env.sudo_password = \"bar\"), the sudo specific passwords will be used.\nNote \nDue to backwards compatibility concerns, user-entered sudo passwords will still be cached into env.password/env.passwords; env.sudo_password/env.sudo_passwords are purely for noninteractive use.\n\n\n[1]\nWe highly recommend the use of SSH key-based access instead of relying on homogeneous password setups, as it鈥檚 significantly more secure.\nLeveraging native SSH config files\nCommand-line SSH clients (such as the one provided by OpenSSH) make use of a specific configuration format typically known as ssh_config, and will read from a file in the platform-specific location $HOME/.ssh/config (or an arbitrary path given to --ssh-config-path/env.ssh_config_path.) This file allows specification of various SSH options such as default or per-host usernames, hostname aliases, and toggling other settings (such as whether to use agent forwarding.)\nFabric鈥檚 SSH implementation allows loading a subset of these options from one鈥檚 actual SSH config file, should it exist. This behavior is not enabled by default (in order to be backwards compatible) but may be turned on by setting env.use_ssh_config to True at the top of your fabfile.\nIf enabled, the following SSH config directives will be loaded and honored by Fabric:\nUser and Port will be used to fill in the appropriate connection parameters when not otherwise specified, in the following fashion:\nGlobally specified User/Port will be used in place of the current defaults (local username and 22, respectively) if the appropriate env vars are not set.\nHowever, if env.user/env.port are set, they override global User/Port values.\nUser/port values in the host string itself (e.g. hostname:222) will override everything, including any ssh_config values.\nHostName can be used to replace the given hostname, just like with regular ssh. So a Host foo entry specifying HostName example.com will allow you to give Fabric the hostname \'foo\' and have that expanded into \'example.com\' at connection time.\nIdentityFile will extend (not replace) env.key_filename.\nForwardAgent will augment env.forward_agent in an 鈥淥R鈥?manner: if either is set to a positive value, agent forwarding will be enabled.\nProxyCommand will trigger use of a proxy command for host connections, just as with regular ssh.\nNote \nIf all you want to do is bounce SSH traffic off a gateway, you may find env.gateway to be a more efficient connection method (which will also honor more Fabric-level settings) than the typical ssh gatewayhost nc %h %p method of using ProxyCommand as a gateway.\nNote \nIf your SSH config file contains ProxyCommand directives and you have set env.gateway to a non-None value, env.gateway will take precedence and the ProxyCommand will be ignored.\nIf one has a pre-created SSH config file, rationale states it will be easier for you to modify env.gateway (e.g. via settings) than to work around your conf file鈥檚 contents entirely.\n\nFabric\n\nPythonic remote execution\n \n \nNavigation\nOverview and Tutorial\nThe environment dictionary, env\nExecution model\nExecution strategy\nDefining tasks\nDefining host lists\nIntelligently executing tasks with execute\nFailure handling\nConnections\nPassword management\nLeveraging native SSH config files\nfab options and arguments\nFabfile construction and use\nInteraction with remote programs\nLibrary Use\nManaging output\nParallel execution\nSSH behavior\nDefining tasks\nColor output functions\nContext Managers\nDecorators\nDocumentation helpers\nNetwork\nOperations\nTasks\nUtils\nConsole Output Utilities\nDjango Integration\nFile and Directory Management\nProject Tools\nRunning Fabric鈥檚 Tests\n\nMain website\nQuick search\n  \nEnter search terms or a module, class or function name. \n\nLove Documentation? Write the Docs is a community full of people like you!\nSponsored 路 Ads served ethically\n\n  v: 1.14',1524046172.02222);
/*!40000 ALTER TABLE `blogs` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `comments`
--

DROP TABLE IF EXISTS `comments`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `comments` (
  `id` varchar(50) NOT NULL,
  `blog_id` varchar(50) NOT NULL,
  `user_id` varchar(50) NOT NULL,
  `user_name` varchar(50) NOT NULL,
  `user_image` varchar(500) NOT NULL,
  `content` mediumtext NOT NULL,
  `created_at` double NOT NULL,
  PRIMARY KEY (`id`),
  KEY `idx_created_at` (`created_at`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `comments`
--

LOCK TABLES `comments` WRITE;
/*!40000 ALTER TABLE `comments` DISABLE KEYS */;
INSERT INTO `comments` VALUES ('0015236931282262bc8567d72394228950344bebbe824a5000','0015236923947921167d942d8b74273a19228809a3ffd34000','00152359682528123fb72adef7342c69a5a661faa5c678e000','w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120','cool',1523693128.22566);
/*!40000 ALTER TABLE `comments` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `users`
--

DROP TABLE IF EXISTS `users`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `users` (
  `id` varchar(50) NOT NULL,
  `email` varchar(50) NOT NULL,
  `passwd` varchar(50) NOT NULL,
  `admin` tinyint(1) NOT NULL,
  `name` varchar(50) NOT NULL,
  `image` varchar(500) NOT NULL,
  `created_at` double NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_email` (`email`),
  KEY `idx_created_at` (`created_at`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `users`
--

LOCK TABLES `users` WRITE;
/*!40000 ALTER TABLE `users` DISABLE KEYS */;
INSERT INTO `users` VALUES ('00152359682528123fb72adef7342c69a5a661faa5c678e000','wenmaohuang@126.com','fee4e85a59f4380bf52e346f65aa95758b939a22',1,'w','http://www.gravatar.com/avatar/016504b84cee81b8f879075f5a14d281?d=mm&s=120',1523596825.28129);
/*!40000 ALTER TABLE `users` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2018-05-09 20:02:25
